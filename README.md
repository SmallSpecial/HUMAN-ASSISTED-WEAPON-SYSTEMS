# Research Practicum 2018 – Research Plan of Group 4

* Group Name: Terminators
* Group participants names: Cabrera, Roberto & Uysal, Ugur
* Project Title: Human-assisted Weapon Systems

## General Introduction

“Twenty years from now, unless we can replace a considerable number of people with robots, it’ll be hard to maintain the current level of war capability,” said Akihisa Nagashima, a former parliamentary vice defence minister and conservative independent lawmaker. “Japan’s (security) situation won’t be more peaceful, so I think this is really serious” (Reuters, 2018). 

Armed forces use technology to gain superiority on the battlefield. Recent breakthroughs in the field of Artificial Intelligence and Unmanned Systems provide new uses for military operations.The Control of Unmanned Systems can be done at different levels of autonomy. The focus of this research is the Human-autonomy teaming approach. In contrast to Manned-unmanned teaming, the unmanned systems are not operated by human operators. With our research we would like to investigate the possibilities to operate unmanned systems semi-autonomously, to increase the effectiveness of military forces on the near future battlefield.

On July 10, 2013, an unmanned X45B drone made an autonomous landing on an aircraft carrier for the first time.
https://www.youtube.com/watch?v=Rc2k6G8LuqY

The military use of autonomous drones in varying degrees of intensity seems to be possible in the foreseeable future.
Our basic principle is that the human military leader remains at any time the decision-making authority to carry out military operations. The question that needs to be clarified is the extent to which humans are cognitively able to monitor unmanned systems and use them in military operationsFurthermore, it has to be clarified how the communication between the military leader and the autonomous system must be defined in order to ensure successful execution of military orders. The purpose of this Research Project is to understand the limits and possibilities of semi-autonomous usage of Unmanned Systems. The focus is on the cognitive performance of the human military leader, who give orders in different military scenarios to the Unmanned System.

This problem is interesting, as the full military potential of Human-autonomy teaming can currently only be estimated, as the technology required for this is just being developed. Therefore we rely as part of our research project on the virtual simulation environment ARMA3, in which a human operator can give orders to several autonomous systems at the same time. With the knowledge, we gain from the simulation experiments we try the answer our research questions. Furthermore, we refer to approaches in this field by other researchers and delineate our approach.

This project makes the following contributions:
* Presentation of the current status of research on Human-autonomy teaming in the military field of application.
* Exploration of the possibilities and limits of Human-autonomy teaming in various military scenarios through simulation experiments.
* Understanding of how the cognitive workload of human in various military Human-autonomy teaming scenarios can be determined.

## Related Work

When searching for literature on the topic of Human-assisted Weapon Systems, we mostly found terms such as Manned-unmanned teaming and Human-autonomy teaming. It is striking that the term Human-autonomy teaming is used more frequently in the latest publications. This is related to advances in the field of autonomous systems in recent years and the resulting potential in the military sector. Manned-unmanned teaming is the collaboration between a system of human inmates and a human remote controlled system without human occupants. In Human-autonomy teaming, the unmanned system is autonomously controlled by an agent or AI and is not remotely controlled by a human operator.

Chen (2018) summarizes recent articles that highlight the growing relevance of using Human-autonomy teaming in the military field. Chen (2018) explains that the Defense Science Board (2016) states that "Intelligent autonomous systems have become increasingly important in military missions" (p.255). Chen (2018) claims that "As these systems become more intelligent and sophisticated - and autonomous - human-autonomy teaming has become a key issue to address "(p.255).

Many research articles focus on ethical and legal aspects of the military use of autonomous systems. 
For example, de Boisboissel (2017) states that "all machines, including autonomous lethal robotic systems, must remain under the tactical control of the military leader" (p.738). According to Chen & Barnes (2014) rules and procedures are designed so that the following ensured: "efficient human supervision of multiple robots, appropriate human trust in the automated systems, maintenance of human operator’s situation awareness, individual differences in human–agent (H-A) interaction, and retention of human decision authority" (p.13).

It is imperative not only to understand the ethical implications of using semi-autonomous entities in war.  There is also a need to understand how a human in a human-autonomy team interacts in the war.  Squire P. N. & Parasuraman R (2010) conducted an experiment in which a human control a determined number of robots in a capturing the flag game.  They collected the data on supervisor (human) task switching performance (complex tasks vs. repetitive tasks) and teams of four and eight robots performance (winning percentage). Squire and Parasuraman wanted to understand how the cognitive load and the Level of Automation (LOA) affected each robot team.  Squire and Parasuraman use the results to established ideas on how to better design an interface that would reduce the cognitive load and become more efficient in conducting tasks.  This experiment is the foundation for the understanding of the human-autonomy teaming interaction.

It is important to emphasize that, in this context, every final decision has to be made by the human, as this topic is also negatively afflicted and can encounter rejection. By coining the term of the technical singularity, Vinge (1993) warned that immediately after the development of Artificial Super Intelligence, the end of humanity would be imminent. Also, Stephen Hawking warned that AI could bring the end to humanity (Hawking 2014). This scenario has also been used in science fiction films, e.g., The Terminator (1984).

## Research Methods (draft)

We want to use Mixed Research Methods to answer research questions related to this projects contributions. In the first step, we want to collect, analyze, and interpret qualitative data through a summary of the results of the related work and interviews with experts in the field of human-autonomy teaming. In the second and third step we want to collect, analyze, and interpret quantitative data through simulation experiments:

Step 1 - Qualitative Methods: 
Presentation of the current status of research on Human-autonomy teaming in the military field of application.
* Summary of the results of the related work 
* Interview with experts on Human-autonomy teaming 
	
Step 2 - Quantitative Methods: 
Exploration of the possibilities and limits of Human-autonomy teaming in various military scenarios through simulation experiments.
* Simulation experiments: Create military scenarios that are viable for human-autonomy teaming experimentation.
* Statistical analysis of the results.
	    
Step 3 - Quantitative Methods: 
Understanding of how the cognitive workload of human in a military Human-autonomy teaming scenario can be determined.
* Simulation experiments: Varying the number of supervised autonomous systems in the most suitable scenario, which was previously examined in step 2.
* Statistical analysis of the results.

Since the full potential of autonomous systems can only be estimated today due to technologies that are not yet fully developed, we want to use a simulation environment in which these technologies are already available. Therefore we use virtual simulation instead of robotics for our experiments.

## References 

* [Chen, J. Y., & Barnes, M. J. (2014). Human–agent teaming for multirobot control: A review of human factors issues. IEEE Transactions on Human-Machine Systems, 44(1), 13-29.](https://ieeexplore.ieee.org/document/6697830/)
* [Chen, J. Y. (2018). Human-autonomy teaming in military settings. Theoretical Issues in Ergonomics Science, 19(3), 255-258.](https://www.tandfonline.com/doi/abs/10.1080/1463922X.2017.1397229)
* [Chen, J. Y., Lakhmani, S. G., Stowers, K., Selkowitz, A. R., Wright, J. L., & Barnes, M. (2018). Situation awareness-based agent transparency and human-autonomy teaming effectiveness. Theoretical issues in ergonomics science, 19(3), 259-282.](https://www.tandfonline.com/doi/abs/10.1080/1463922X.2017.1315750)
* [de Boisboissel, G. (2017). Is it sensible to grant autonomous decision-making to military robots of the future?. In Military Technologies (ICMT), 2017 International Conference on (pp. 738-742). IEEE.](https://ieeexplore.ieee.org/document/7988854/)
* [Defense Science Board. 2016. Defense Science Board Summer Study on Autonomy. Washington, DC:Under Secretary of Defense.](https://www.hsdl.org/?view&did=794641)
* [Endsley, M. R. (2017). From here to autonomy: lessons learned from human–automation research. Human factors, 59(1), 5-27.](http://journals.sagepub.com/doi/10.1177/0018720816681350)
* [Hawking, S. (2014). Transcendence looks at the implications of artificial intelligence—but are we taking AI seriously enough? The Independent.](https://www.independent.co.uk/news/science/stephen-hawking-transcendence-looks-at-the-implications-of-artificial-intelligence-but-are-we-taking-9313474.html)
* [Millington, I., & Funge, J. (2009). Artificial intelligence for games. CRC Press.](https://www.crcpress.com/Artificial-Intelligence-for-Games/Millington-Millington-Funge/p/book/9780123747310)
* [Reuters (2018, September 19). Ageing Japan: Military recruiters struggle as applicant pool dries up. Retrieved from https://in.reuters.com/article/japan-ageing-military-recruits/ageing-japan-military-recruiters-struggle-as-applicant-pool-dries-up-idINKCN1LZ146](https://in.reuters.com/article/japan-ageing-military-recruits/ageing-japan-military-recruiters-struggle-as-applicant-pool-dries-up-idINKCN1LZ146)
* [Sadraey, M. H. (2018). Manned-unmanned aircraft teaming. In 2018 IEEE Aerospace Conference (pp. 1-12). IEEE.](https://ieeexplore.ieee.org/document/8396747/)
* [Scharre, P. (2018). Army of None: Autonomous Weapons and the Future of War. WW Norton & Company.](https://books.google.com/books?hl=de&lr=&id=sjMsDwAAQBAJ&oi=fnd&pg=PT7&dq=Army+of+None&ots=T8z0gGG0IW&sig=nIZIAWaqnNoPhMiFCTqo5gdNHeY#v=onepage&q=Army%20of%20None&f=false)
* [Squire, P. N., & Parasuraman, R. (2010). Effects of automation and task load on task switching during human supervision of multiple semi-autonomous robots in a dynamic environment. Ergonomics, 53(8), 951-961.](https://www.tandfonline.com/doi/full/10.1080/00140139.2010.489969)
* [Vinge, V. (1993). The coming technological singularity: How to survive in the post-human era.](https://edoras.sdsu.edu/~vinge/misc/singularity.html)
* [Warren, A., & Hillas, A. (2017). Lethal Autonomous Weapons Systems: Adapting to the Future Unmanned Warfare and Unaccountable Robots. Yale J. Int'l Aff., 12, 71.](https://heinonline.org/HOL/LandingPage?handle=hein.journals/yaljoina12&div=12&id=&page=)
* [Yilmaz, L., Ören, T., & Aghaee, N. G. (2006). Intelligent agents, simulation, and gaming. Simulation & Gaming, 37(3), 339-349.](http://journals.sagepub.com/doi/abs/10.1177/1046878106289089)
